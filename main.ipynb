{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399869f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import model_get\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebf3d1",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc1747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def loadGlove(inputpath, outputpath=\"\"):\n",
    "    data_list = []\n",
    "    wordEmb = {}\n",
    "    with open(inputpath) as f:\n",
    "        for line in f:\n",
    "            ll = line.strip().split(',')\n",
    "            ll[0] = str(int(float(ll[0])))\n",
    "            data_list.append(ll)\n",
    "\n",
    "            ll_new = [float(i) for i in ll]\n",
    "            emb = np.array(ll_new[1:], dtype=\"float32\")\n",
    "            wordEmb[str(int(ll_new[0]))] = emb\n",
    "\n",
    "    if outputpath != \"\":\n",
    "        with open(outputpath) as f:\n",
    "            for data in data_list:\n",
    "                f.writelines(' '.join(data))\n",
    "    return wordEmb\n",
    "\n",
    "\n",
    "def plotPrecisionRecallCurve(estimators, labels, xtests, ytests, flnm, icol=1):\n",
    "    indx = 0\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    for estimator in estimators:\n",
    "        if len(ytests[indx].shape) == 2:\n",
    "            pre, rec, _ = precision_recall_curve(\n",
    "                ytests[indx][:, icol],\n",
    "                estimator.predict(xtests[indx])[:, icol],\n",
    "                pos_label=icol)\n",
    "        else:\n",
    "            pre, rec, _ = precision_recall_curve(\n",
    "                ytests[indx],\n",
    "                estimator.predict_proba(xtests[indx])[:, icol],\n",
    "                pos_label=icol)\n",
    "        #\n",
    "        plt.plot(\n",
    "            rec, pre,\n",
    "            label=labels[indx] + ' (AUC: %s \\u00B1 0.001)' % (\n",
    "                np.round(auc(rec, pre), 3))\n",
    "        )\n",
    "        indx += 1\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(flnm)\n",
    "\n",
    "\n",
    "def plotRocCurve(\n",
    "        estimators, labels,\n",
    "        xtests, ytests,\n",
    "        flnm, icol=1):\n",
    "    indx = 0\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    for estimator in estimators:\n",
    "        if len(ytests[indx].shape) == 2:\n",
    "            fprs, tprs, _ = roc_curve(\n",
    "                ytests[indx][:, icol],\n",
    "                estimator.predict(xtests[indx])[:, icol]\n",
    "            )\n",
    "        else:\n",
    "            fprs, tprs, _ = roc_curve(\n",
    "                ytests[indx],\n",
    "                estimator.predict_proba(xtests[indx])[:, icol]\n",
    "            )\n",
    "        # print(estimator)\n",
    "        plt.plot(\n",
    "            fprs, tprs,\n",
    "            label=labels[indx] + ' (AUC: %s \\u00B1 0.001)' % (\n",
    "                np.round(auc(fprs, tprs), 3))\n",
    "        )\n",
    "        indx += 1\n",
    "    #\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(flnm)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4215027",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85807246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.0001,\n",
    "    patience=10, verbose=0, mode='auto')\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "dataset = 'hek293t'\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    "batch_size = 128#64\n",
    "flpath = 'data/'\n",
    "\n",
    "\n",
    "retrain = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b64267",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6b9c6",
   "metadata": {},
   "source": [
    "CrisprIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crispr_ip_model\n",
      "load data!\n",
      "encodedposition9x23hek293t.pkl\n",
      "36306\n",
      "xtrain shape: (36636, 1, 23, 9)\n",
      "36636 train samples\n",
      "11449 test samples\n",
      "9160 val samples\n",
      "330\n",
      "36306\n",
      "568.0\n",
      "Training!!\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "print('crispr_ip_model')\n",
    "encoder_shape = (23, 9)\n",
    "seg_len, coding_dim = encoder_shape\n",
    "\n",
    "open_name = 'encodedposition9x23' + dataset + '.pkl'\n",
    "\n",
    "\n",
    "print('load data!')\n",
    "print(open_name)\n",
    "\n",
    "loaddata = pkl.load(\n",
    "    open(flpath + open_name, 'rb'),\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(loaddata.images),\n",
    "    loaddata.target,  # loaddata.target,\n",
    "    stratify=pd.Series(loaddata.target),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,  # loaddata.target,\n",
    "    stratify=pd.Series(y_train),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "neg = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "print(neg)\n",
    "\n",
    "\n",
    "\n",
    "xtrain, xtest1, ytrain, ytest1, xval, yval, inputshape = model_get.transformIO(\n",
    "    x_train, x_test, y_train, y_test, x_val, y_val, seg_len, coding_dim, num_classes)\n",
    "\n",
    "pos_indices = y_train == 1\n",
    "pos_x, neg_x = xtrain[pos_indices], xtrain[~pos_indices]\n",
    "pos_y, neg_y = ytrain[pos_indices], ytrain[~pos_indices]\n",
    "print(len(pos_y))\n",
    "print(len(neg_y))\n",
    "\n",
    "pos_ds = tf.data.Dataset.from_tensor_slices((pos_x, pos_y)).repeat()\n",
    "neg_ds = tf.data.Dataset.from_tensor_slices((neg_x, neg_y)).repeat()\n",
    "\n",
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5], seed=seed)\n",
    "resampled_ds = resampled_ds.batch(batch_size).prefetch(2)\n",
    "resampled_steps_per_epoch = np.ceil(2 * neg / batch_size)\n",
    "print(resampled_steps_per_epoch)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).cache()\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "\n",
    "print('Training!!')\n",
    "\n",
    "crispr_ip_model = model_get.crispr_ip(test_ds, resampled_steps_per_epoch, resampled_ds, xtrain, ytrain,\n",
    "                                       xtest1,\n",
    "                                       ytest1,\n",
    "                                       inputshape, num_classes, batch_size, epochs, callbacks,\n",
    "                                       open_name, retrain)\n",
    "\n",
    "yscore = crispr_ip_model.predict(xtest1)\n",
    "ypred = np.argmax(yscore, axis=1)\n",
    "yscore = yscore[:, 1]\n",
    "ytest = np.argmax(ytest1, axis=1)\n",
    "eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
    "eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
    "eval_fun_types = [True, True, True, True, False, False]\n",
    "for index_f, function in enumerate(eval_funs):\n",
    "    if eval_fun_types[index_f]:\n",
    "        score = np.round(function(ytest, ypred), 4)\n",
    "    else:\n",
    "        score = np.round(function(ytest, yscore), 4)\n",
    "    print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95348ec",
   "metadata": {},
   "source": [
    "cnn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f00f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_std\n",
      "load data!\n",
      "encoded4x23hek293t.pkl\n",
      "36306\n",
      "xtrain shape: (36636, 1, 23, 4)\n",
      "36636 train samples\n",
      "11449 test samples\n",
      "9160 xval samples\n",
      "330\n",
      "36306\n",
      "568.0\n",
      "Training!!\n",
      "Accuracy                0.7696\n",
      "F1 score                0.0157\n",
      "Precision               0.0081\n",
      "Recall                  0.2039\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-56492ae8b950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{:<15}{:>15}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_fun_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\reviewcrispr\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\reviewcrispr\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[1;32mE:\\anaconda\\envs\\reviewcrispr\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\reviewcrispr\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 721\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\reviewcrispr\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n\u001b[1;32m--> 106\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    107\u001b[0m             )\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "print('cnn_std')\n",
    "encoder_shape = (23, 4)\n",
    "seg_len, coding_dim = encoder_shape\n",
    "open_name = 'encoded4x23' + dataset + '.pkl'\n",
    "\n",
    "print('load data!')\n",
    "print(open_name)\n",
    "\n",
    "loaddata = pkl.load(\n",
    "    open(flpath + open_name, 'rb'),\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(loaddata.images),\n",
    "    loaddata.target,\n",
    "    stratify=pd.Series(loaddata.target),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify=pd.Series(y_train),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "neg = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "print(neg)\n",
    "\n",
    "xtrain, xtest2, ytrain, ytest2, xval, yval, input_shape = model_get.cnn_std_transformIO(x_train, x_test,\n",
    "                                                                                         y_train,\n",
    "                                                                                         y_test, x_val, y_val,\n",
    "                                                                                         seg_len, coding_dim,\n",
    "                                                                                         num_classes)\n",
    "pos_indices = y_train == 1\n",
    "pos_x, neg_x = xtrain[pos_indices], xtrain[~pos_indices]\n",
    "pos_y, neg_y = ytrain[pos_indices], ytrain[~pos_indices]\n",
    "print(len(pos_y))\n",
    "print(len(neg_y))\n",
    "\n",
    "pos_ds = tf.data.Dataset.from_tensor_slices((pos_x, pos_y)).repeat()\n",
    "neg_ds = tf.data.Dataset.from_tensor_slices((neg_x, neg_y)).repeat()\n",
    "\n",
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5], seed=seed)\n",
    "resampled_ds = resampled_ds.batch(batch_size).prefetch(2)\n",
    "resampled_steps_per_epoch = np.ceil(2 * neg / batch_size)\n",
    "print(resampled_steps_per_epoch)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).cache()\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print('Training!!')\n",
    "\n",
    "cnn_std_model = model_get.cnn_std(test_ds, resampled_steps_per_epoch, resampled_ds, xtrain, ytrain,\n",
    "                                   xtest2,\n",
    "                                   ytest2, num_classes, batch_size, epochs, callbacks,\n",
    "                                   open_name, retrain)\n",
    "\n",
    "yscore = cnn_std_model.predict(xtest2)\n",
    "ypred = np.argmax(yscore, axis=1)\n",
    "yscore = yscore[:, 1]\n",
    "ytest = np.argmax(ytest2, axis=1)\n",
    "eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
    "eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
    "eval_fun_types = [True, True, True, True, False, False]\n",
    "for index_f, function in enumerate(eval_funs):\n",
    "    if eval_fun_types[index_f]:\n",
    "        score = np.round(function(ytest, ypred), 4)\n",
    "    else:\n",
    "        score = np.round(function(ytest, yscore), 4)\n",
    "    print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996d56f",
   "metadata": {},
   "source": [
    "crisprDNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e61341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('crisprDNT')\n",
    "open_name = 'encodedmismatchtype14x23' + dataset + '.pkl'\n",
    "encoder_shape = (23, 14)\n",
    "seg_len, coding_dim = encoder_shape\n",
    "\n",
    "print('load data!')\n",
    "print(open_name)\n",
    "\n",
    "loaddata = pkl.load(\n",
    "    open(flpath + open_name, 'rb'),\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    loaddata.images,\n",
    "    loaddata.target,\n",
    "    stratify=pd.Series(loaddata.target),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify=pd.Series(y_train),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "neg = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "print(neg)\n",
    "\n",
    "xtrain, xtest3, ytrain, ytest3, xval, yval, inputshape = model_get.transformIO(\n",
    "    x_train, x_test, y_train, y_test, x_val, y_val, seg_len, coding_dim, num_classes)\n",
    "\n",
    "pos_indices = y_train == 1\n",
    "pos_x, neg_x = xtrain[pos_indices], xtrain[~pos_indices]\n",
    "pos_y, neg_y = ytrain[pos_indices], ytrain[~pos_indices]\n",
    "print(len(pos_y))\n",
    "print(len(neg_y))\n",
    "pos_ds = tf.data.Dataset.from_tensor_slices((pos_x, pos_y)).repeat()\n",
    "neg_ds = tf.data.Dataset.from_tensor_slices((neg_x, neg_y)).repeat()\n",
    "\n",
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5], seed=seed)\n",
    "resampled_ds = resampled_ds.batch(batch_size).prefetch(2)\n",
    "resampled_steps_per_epoch = np.ceil(2 * neg / batch_size)\n",
    "print(resampled_steps_per_epoch)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).cache()\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print('Training!!')\n",
    "\n",
    "crisprDNT = model_get.crisprDNT(test_ds, resampled_steps_per_epoch, resampled_ds, xtrain, ytrain,\n",
    "                                     xtest3,\n",
    "                                     ytest3,\n",
    "                                     inputshape, num_classes, batch_size, epochs, callbacks,\n",
    "                                     open_name, retrain)\n",
    "\n",
    "yscore = new_model.predict(xtest3)\n",
    "ypred = np.argmax(yscore, axis=1)\n",
    "yscore = yscore[:, 1]\n",
    "ytest = np.argmax(ytest3, axis=1)\n",
    "eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
    "eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
    "eval_fun_types = [True, True, True, True, False, False]\n",
    "for index_f, function in enumerate(eval_funs):\n",
    "    if eval_fun_types[index_f]:\n",
    "        score = np.round(function(ytest, ypred), 4)\n",
    "    else:\n",
    "        score = np.round(function(ytest, yscore), 4)\n",
    "    print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee68598",
   "metadata": {},
   "source": [
    "crisprNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c705a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CRISPR_Net')\n",
    "open_name = 'encoded6x23' + dataset + '.pkl'\n",
    "encoder_shape = (23, 6)\n",
    "seg_len, coding_dim = encoder_shape\n",
    "print('load data!')\n",
    "print(open_name)\n",
    "loaddata = pkl.load(\n",
    "    open(flpath + open_name, 'rb'),\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    loaddata.images,\n",
    "    loaddata.target,\n",
    "    stratify=pd.Series(loaddata.target),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify=pd.Series(y_train),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "neg = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "print(neg)\n",
    "\n",
    "xtrain, xtest4, ytrain, ytest4, xval, yval, inputshape = model_get.CRISPR_Net_transformIO(\n",
    "    x_train, x_test, y_train, y_test, x_val, y_val, seg_len, coding_dim, num_classes)\n",
    "\n",
    "pos_indices = y_train == 1\n",
    "pos_x, neg_x = xtrain[pos_indices], xtrain[~pos_indices]\n",
    "pos_y, neg_y = ytrain[pos_indices], ytrain[~pos_indices]\n",
    "print(len(pos_y))\n",
    "print(len(neg_y))\n",
    "\n",
    "pos_ds = tf.data.Dataset.from_tensor_slices((pos_x, pos_y)).repeat()\n",
    "neg_ds = tf.data.Dataset.from_tensor_slices((neg_x, neg_y)).repeat()\n",
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5], seed=seed)\n",
    "resampled_ds = resampled_ds.batch(batch_size).prefetch(2)\n",
    "\n",
    "resampled_steps_per_epoch = np.ceil(2 * neg / batch_size)\n",
    "print(resampled_steps_per_epoch)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).cache()\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print('Training!!')\n",
    "\n",
    "CRISPR_Net_model = model_get.CRISPR_Net_model(test_ds, resampled_steps_per_epoch, resampled_ds,\n",
    "                                               xtrain, ytrain,\n",
    "                                               xtest4,\n",
    "                                               ytest4,\n",
    "                                               inputshape, num_classes, batch_size, epochs, callbacks,\n",
    "                                               open_name, retrain)\n",
    "yscore = CRISPR_Net_model.predict(xtest4)\n",
    "ypred = np.argmax(yscore, axis=1)\n",
    "yscore = yscore[:, 1]\n",
    "ytest = np.argmax(ytest4, axis=1)\n",
    "eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
    "eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
    "eval_fun_types = [True, True, True, True, False, False]\n",
    "for index_f, function in enumerate(eval_funs):\n",
    "    if eval_fun_types[index_f]:\n",
    "        score = np.round(function(ytest, ypred), 4)\n",
    "    else:\n",
    "        score = np.round(function(ytest, yscore), 4)\n",
    "    print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aff28",
   "metadata": {},
   "source": [
    "cnnCRISPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cnn_crispr model')\n",
    "print(\"GloVe model loaded\")\n",
    "VOCAB_SIZE = 16  # 4**3\n",
    "EMBED_SIZE = 100\n",
    "glove_inputpath = \"data/keras_GloVeVec_\" + dataset + \"_5_100_10000.csv\"\n",
    "# load GloVe model\n",
    "model_glove = loadGlove(glove_inputpath)\n",
    "embedding_weights = np.zeros((VOCAB_SIZE, EMBED_SIZE))\n",
    "for i in range(VOCAB_SIZE):\n",
    "    embedding_weights[i, :] = model_glove[str(i)]\n",
    "\n",
    "open_name = 'encoded_CnnCrispr_' + dataset + '.pkl'\n",
    "\n",
    "\n",
    "print('load data!')\n",
    "print('load data!')\n",
    "print(open_name)\n",
    "\n",
    "loaddata = pkl.load(\n",
    "    open(flpath + open_name, 'rb'),\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(loaddata.images),\n",
    "    loaddata.target,\n",
    "    stratify=pd.Series(loaddata.target),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify=pd.Series(y_train),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "neg = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        neg += 1\n",
    "print(neg)\n",
    "\n",
    "xtrain, xtest5, ytrain, ytest5, xval, yval = model_get.offt_transformIO(x_train, x_test, y_train, y_test,\n",
    "                                                                         x_val, y_val, num_classes)\n",
    "\n",
    "pos_indices = y_train == 1\n",
    "pos_x, neg_x = xtrain[pos_indices], xtrain[~pos_indices]\n",
    "pos_y, neg_y = ytrain[pos_indices], ytrain[~pos_indices]\n",
    "print(len(pos_y))\n",
    "print(len(neg_y))\n",
    "\n",
    "pos_ds = tf.data.Dataset.from_tensor_slices((pos_x, pos_y)).repeat()\n",
    "neg_ds = tf.data.Dataset.from_tensor_slices((neg_x, neg_y)).repeat()\n",
    "\n",
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5], seed=seed)\n",
    "resampled_ds = resampled_ds.batch(batch_size).prefetch(2)\n",
    "resampled_steps_per_epoch = np.ceil(2 * neg / batch_size)\n",
    "print(resampled_steps_per_epoch)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((xval, yval)).cache()\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print('Training!!')\n",
    "\n",
    "CnnCrispr_model = model_get.CnnCrispr(embedding_weights, test_ds, resampled_steps_per_epoch, resampled_ds,\n",
    "                                       xtrain, ytrain,\n",
    "                                       xtest5,\n",
    "                                       ytest5, num_classes, batch_size, epochs, callbacks,\n",
    "                                       open_name, retrain)\n",
    "\n",
    "yscore = CnnCrispr_model.predict(xtest5)\n",
    "ypred = np.argmax(yscore, axis=1)\n",
    "yscore = yscore[:, 1]\n",
    "ytest = np.argmax(ytest5, axis=1)\n",
    "eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
    "eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
    "eval_fun_types = [True, True, True, True, False, False]\n",
    "for index_f, function in enumerate(eval_funs):\n",
    "    if eval_fun_types[index_f]:\n",
    "        score = np.round(function(ytest, ypred), 4)\n",
    "    else:\n",
    "        score = np.round(function(ytest, yscore), 4)\n",
    "    print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ee5d4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5894f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ crispr_ip_model, cnn_std_model, crisprDNT, CRISPR_Net_model, CnnCrispr_model]\n",
    "\n",
    "labels = ['CRISPR_IP', 'CNN_std', 'CrisprDNT', 'CRISPR_Net', 'CnnCrispr']\n",
    "\n",
    "xtests = [xtest1, xtest2, xtest3, xtest4, xtest5]\n",
    "\n",
    "ytests = [ytest1, ytest2, ytest3, ytest4, ytest5]\n",
    "\n",
    "roc_name = 'roccurve_compare_' + dataset + '.pdf'\n",
    "pr_name = 'precisionrecallcurve_compare_' + dataset + '.pdf'\n",
    "\n",
    "plotRocCurve(models, labels, xtests, ytests, roc_name)\n",
    "\n",
    "plotPrecisionRecallCurve(models, labels, xtests, ytests, pr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [  cnn_std_model,  CRISPR_Net_model, CnnCrispr_model]\n",
    "\n",
    "labels = [ 'CNN_std',  'CRISPR_Net', 'CnnCrispr']\n",
    "\n",
    "xtests = [ xtest2,  xtest4, xtest5]\n",
    "\n",
    "ytests = [ ytest2,  ytest4, ytest5]\n",
    "\n",
    "roc_name = 'roccurve_compare_' + dataset + '.pdf'\n",
    "pr_name = 'precisionrecallcurve_compare_' + dataset + '.pdf'\n",
    "\n",
    "plotRocCurve(models, labels, xtests, ytests, roc_name)\n",
    "\n",
    "plotPrecisionRecallCurve(models, labels, xtests, ytests, pr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063d0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
